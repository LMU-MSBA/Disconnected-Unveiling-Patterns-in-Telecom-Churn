# setting up lists of hyperparameters
loss1  = ['exponential', 'log_loss']
n_estimators1 = [50, 100, 150, 200, 250, 300]
learning_rate1 = [0.01, 0.1, 0.5, 1]
max_depth1 = [2, 4, 6, 8, 10, 12, 14, 16]
min_samples_leaf1 = [5, 10, 15, 20, 25, 30, 35, 40]
max_features1 = [None, 'sqrt', 'log2', 0.3 , 0.4, 0.5, 0.6, 0.7, 0.8]

# run 1
results1 = []
for loss in loss1:
    model = GradientBoostingClassifier(loss = loss)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results1.append(accuracy)

print(results1)
print('--------------')
print(max(results1))   # just making it easier to see the best accuracy

# run 2
results2 = []
for n_estimators in n_estimators1:
    model = GradientBoostingClassifier(n_estimators = n_estimators)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results2.append(accuracy)

print(results2)
print('--------------')
print(max(results2))

# run 3
results3 = []
for learning_rate in learning_rate1:
    model = GradientBoostingClassifier(loss = 'log_loss', n_estimators = 150, learning_rate = learning_rate)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results3.append(accuracy)

print(results3)
print('--------------')
print(max(results3))

# run 4
results4 = []
for max_depth in max_depth1:
    model = GradientBoostingClassifier(loss = 'log_loss', n_estimators = 150, learning_rate = 0.1, max_depth = max_depth)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results4.append(accuracy)

print(results4)
print('--------------')
print(max(results4))

# run 5
results5 = []
for min_samples_leaf in min_samples_leaf1:
    model = GradientBoostingClassifier(loss = 'log_loss', n_estimators = 150, learning_rate = 0.1, max_depth = 2, min_samples_leaf = min_samples_leaf)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results5.append(accuracy)

print(results5)
print('--------------')
print(max(results5))

# run 6
results6 = []
for max_features in max_features1:
    model = GradientBoostingClassifier(loss = 'log_loss', n_estimators = 150, learning_rate = 0.1, max_depth = 2, min_samples_leaf = 10, max_features = max_features)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = np.mean(y_test == y_pred)
    results6.append(accuracy)

print(results6)
print('--------------')
print(max(results6))
